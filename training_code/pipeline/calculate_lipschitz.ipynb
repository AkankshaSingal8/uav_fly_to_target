{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 14:54:45.294673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Sequence, Optional, Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras_models import generate_ncp_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import ndarray\n",
    "from tensorflow.python.keras.models import Functional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hidden_list(model: Functional, return_numpy: bool = True):\n",
    "    print(model.input_shape)\n",
    "    constructor = np.zeros if return_numpy else tf.zeros\n",
    "    hiddens = []\n",
    "    if len(model.input_shape)==1:\n",
    "        lool = model.input_shape[0][1:]\n",
    "    else:\n",
    "        lool = model.input_shape[1:]\n",
    "    print(lool)\n",
    "    for input_shape in lool:  # ignore 1st output, as is this control output\n",
    "        hidden = []\n",
    "        for i, shape in enumerate(input_shape):\n",
    "            if shape is None:\n",
    "                if i == 0:  # batch dim\n",
    "                    hidden.append(1)\n",
    "                    continue\n",
    "                elif i == 1:  # seq len dim\n",
    "                    hidden.append(0)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Unable to infer hidden state shape. Leaving as none\")\n",
    "            hidden.append(shape)\n",
    "        hiddens.append(constructor(hidden))\n",
    "    return hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path: str, img_shape: Tuple[int, int, int], reverse_channels: bool = True) -> Optional[ndarray]:\n",
    "    img = PIL.Image.open(img_path)\n",
    "    if img is not None:\n",
    "        # image shape is height, width, PIL takes width, height\n",
    "        resized = img.resize(img_shape[:2][::-1], PIL.Image.BILINEAR)\n",
    "        img_numpy = tf.keras.preprocessing.image.img_to_array(resized).astype(np.uint8)\n",
    "        if reverse_channels:\n",
    "            # reverse channels of image to match training\n",
    "            img_numpy = img_numpy[..., ::-1]\n",
    "\n",
    "        # add batch dim\n",
    "        img_numpy = np.expand_dims(img_numpy, axis=0)\n",
    "        return img_numpy\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def image_dir_generator(data_path: str, image_shape: Tuple[int, int, int], reverse_channels: bool = False):\n",
    "    \n",
    "    contents = os.listdir(data_path)\n",
    "    contents = [os.path.join(data_path, c) for c in contents if 'png' in c]\n",
    "    contents.sort()\n",
    "    for path in contents:\n",
    "        img = load_image(img_path=path, img_shape=image_shape, reverse_channels=reverse_channels)\n",
    "        if img is not None:\n",
    "            yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 14:54:53.882479: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-10-04 14:54:53.883183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-10-04 14:54:53.906638: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-10-04 14:54:53.906659: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: iras-hub\n",
      "2024-10-04 14:54:53.906666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: iras-hub\n",
      "2024-10-04 14:54:53.906756: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 550.54.14\n",
      "2024-10-04 14:54:53.906773: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 550.54.14\n",
      "2024-10-04 14:54:53.906779: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 550.54.14\n",
      "2024-10-04 14:54:53.907112: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 14:54:53.908070: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 144, 256, 3), (None, 34)]\n",
      "[(None, 34)]\n",
      "hidden [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2024-10-04 14:54:54.475982: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-10-04 14:54:54.492426: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000260000 Hz\n",
      "832it [00:28, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.10736777, 0.09390518, 0.51793343, 0.19179153, 0.35834986,\n",
      "       0.49816179, 0.52820468, 0.19368741, 0.07618143, 0.04062793,\n",
      "       0.28867343, 0.10671288, 0.06689268, 1.25927126, 0.59002292,\n",
      "       0.07122275, 0.04867452, 0.3279714 , 0.39318371, 0.93345183,\n",
      "       0.46152639, 0.35753256, 0.62972325, 0.26788479, 0.93245256,\n",
      "       0.74350893, 0.78686345, 0.99237657, 0.93485636, 0.24223337,\n",
      "       0.10485464, 0.14562921, 0.10232146, 0.65539438])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reverse_channels = False\n",
    "sequence_path = \"../../fly_to_target_dataset/dataset/1\"\n",
    "\n",
    "IMAGE_SHAPE = (144, 256, 3)\n",
    "IMAGE_SHAPE_CV = (IMAGE_SHAPE[1], IMAGE_SHAPE[0])\n",
    "\n",
    "batch_size = None\n",
    "seq_len = 64\n",
    "augmentation_params = None\n",
    "single_step = True\n",
    "no_norm_layer = False\n",
    "DROPOUT = 0.1\n",
    "\n",
    "DEFAULT_NCP_SEED = 22222\n",
    "\n",
    "mymodel = generate_ncp_model(seq_len, IMAGE_SHAPE, augmentation_params, batch_size, DEFAULT_NCP_SEED, single_step, no_norm_layer)\n",
    "\n",
    "mymodel.load_weights('../saved_models/retrain_difftraj_wscheduler0.85_seed22222_lr0.001_trainloss0.00016_valloss0.13141_diffcoreset900.h5')\n",
    "\n",
    "hiddens = generate_hidden_list(model=mymodel, return_numpy=True)\n",
    "print(\"hidden\", hiddens)\n",
    "\n",
    "all_hiddens = []  # list of list of arrays with shape num_timesteps x num_hiddens x hidden_dim\n",
    "for i, img in tqdm(enumerate(image_dir_generator(sequence_path, IMAGE_SHAPE, reverse_channels))):\n",
    "    all_hiddens.append(hiddens)\n",
    "    out = mymodel.predict([img, *hiddens])\n",
    "    hiddens = out[1:]  # list num_hidden long, each el is hidden_dim,\n",
    "\n",
    "# print(\"all_hiddens\", all_hiddens)\n",
    "# flatten batch dim\n",
    "all_hiddens = [[np.squeeze(hid, axis=0) for hid in step_hid] for step_hid in all_hiddens]\n",
    "# print(\"all_hiddens\", all_hiddens)\n",
    "# crete list with same shape as hidden vectors where contents are lipschitz values of each dimension\n",
    "lip = [np.zeros_like(h) for h in all_hiddens[0]]\n",
    "for i in range(len(all_hiddens) - 1):\n",
    "    current_hiddens = all_hiddens[i]\n",
    "    next_hiddens = all_hiddens[i + 1]\n",
    "    diff = [np.abs(n - c) for n, c in zip(next_hiddens, current_hiddens)]\n",
    "    lip = [np.maximum(l, d) for l, d in zip(lip, diff)]\n",
    "print(lip)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

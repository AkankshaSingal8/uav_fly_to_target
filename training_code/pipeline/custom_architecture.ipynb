{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import kerasncp as kncp\n",
    "\n",
    "import os\n",
    "from typing import Iterable, Dict\n",
    "import tensorflow as tf\n",
    "import kerasncp as kncp\n",
    "from kerasncp.tf import LTCCell, WiredCfcCell\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras_models import generate_ncp_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.1\n",
    "\n",
    "DEFAULT_NCP_SEED = 22222\n",
    "\n",
    "IMAGE_SHAPE = (144, 256, 3)\n",
    "IMAGE_SHAPE_CV = (IMAGE_SHAPE[1], IMAGE_SHAPE[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_augmentation_layers(x, augmentation_params: Dict, single_step: bool):\n",
    "    # translate -> rotate -> zoom -> noise\n",
    "    trans = augmentation_params.get('translation', None)\n",
    "    rot = augmentation_params.get('rotation', None)\n",
    "    zoom = augmentation_params.get('zoom', None)\n",
    "    noise = augmentation_params.get('noise', None)\n",
    "\n",
    "    if trans is not None:\n",
    "        x = wrap_time(keras.layers.experimental.preprocessing.RandomTranslation(\n",
    "            height_factor=trans, width_factor=trans), single_step)(x)\n",
    "\n",
    "    if rot is not None:\n",
    "        x = wrap_time(keras.layers.experimental.preprocessing.RandomRotation(rot), single_step)(x)\n",
    "\n",
    "    if zoom is not None:\n",
    "        x = wrap_time(keras.layers.experimental.preprocessing.RandomZoom(\n",
    "            height_factor=zoom, width_factor=zoom), single_step)(x)\n",
    "\n",
    "    if noise:\n",
    "        x = wrap_time(keras.layers.GaussianNoise(stddev=noise), single_step)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def generate_normalization_layers(x, single_step: bool):\n",
    "    rescaling_layer = keras.layers.experimental.preprocessing.Rescaling(1. / 255)\n",
    "\n",
    "    normalization_layer = keras.layers.experimental.preprocessing.Normalization(\n",
    "        mean=[0.6042006463205742, 0.6042006463205742, 0.6042006880578502],\n",
    "        variance=[0.0103, 0.0103, 0.0103])\n",
    "\n",
    "    x = rescaling_layer(x)\n",
    "    x = wrap_time(normalization_layer, single_step)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def wrap_time(layer, single_step: bool):\n",
    "    \"\"\"\n",
    "    Helper function that wraps layer in a timedistributed or not depending on the arguments of this function\n",
    "    \"\"\"\n",
    "    if not single_step:\n",
    "        return keras.layers.TimeDistributed(layer)\n",
    "    else:\n",
    "        return layer\n",
    "\n",
    "\n",
    "def generate_network_trunk(seq_len,\n",
    "                           image_shape,\n",
    "                           augmentation_params: Dict = None,\n",
    "                           batch_size=None,\n",
    "                           single_step: bool = False,\n",
    "                           no_norm_layer: bool = False, ):\n",
    "    \n",
    "\n",
    "    if single_step:\n",
    "        inputs = keras.Input(shape=image_shape)\n",
    "    else:\n",
    "        inputs = keras.Input(batch_input_shape=(batch_size, seq_len, *image_shape))\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    if not no_norm_layer:\n",
    "        x = generate_normalization_layers(x, single_step)\n",
    "\n",
    "    if augmentation_params is not None:\n",
    "        x = generate_augmentation_layers(x, augmentation_params, single_step)\n",
    "\n",
    "    # Conv Layers\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=24, kernel_size=(5, 5), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=36, kernel_size=(5, 5), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=48, kernel_size=(5, 5), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "\n",
    "    # fully connected layers\n",
    "    x = wrap_time(keras.layers.Flatten(), single_step)(x)\n",
    "    x = wrap_time(keras.layers.Dense(units=128, activation='linear'), single_step)(x)\n",
    "    x = wrap_time(keras.layers.Dropout(rate=DROPOUT), single_step)(x)\n",
    "\n",
    "    return inputs, x"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

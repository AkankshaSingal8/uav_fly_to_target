{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 10:46:00.912871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import kerasncp as kncp\n",
    "\n",
    "import os\n",
    "from typing import Iterable, Dict\n",
    "import tensorflow as tf\n",
    "import kerasncp as kncp\n",
    "from kerasncp.tf import LTCCell, WiredCfcCell\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras_models import generate_ncp_model\n",
    "from train_test_loader import get_dataset_multi, get_val_dataset_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_root = \"../../fly_to_target_dataset/diff_coreset\"\n",
    "val_root = \"../../fly_to_target_dataset/test_data\"\n",
    "DROPOUT = 0.1\n",
    "\n",
    "DEFAULT_NCP_SEED = 22222\n",
    "\n",
    "IMAGE_SHAPE = (144, 256, 3)\n",
    "IMAGE_SHAPE_CV = (IMAGE_SHAPE[1], IMAGE_SHAPE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmentation_layers(x, augmentation_params: Dict, single_step: bool):\n",
    "    # translate -> rotate -> zoom -> noise\n",
    "    trans = augmentation_params.get('translation', None)\n",
    "    rot = augmentation_params.get('rotation', None)\n",
    "    zoom = augmentation_params.get('zoom', None)\n",
    "    noise = augmentation_params.get('noise', None)\n",
    "\n",
    "    if trans is not None:\n",
    "        x = wrap_time(keras.layers.experimental.preprocessing.RandomTranslation(\n",
    "            height_factor=trans, width_factor=trans), single_step)(x)\n",
    "\n",
    "    if rot is not None:\n",
    "        x = wrap_time(keras.layers.experimental.preprocessing.RandomRotation(rot), single_step)(x)\n",
    "\n",
    "    if zoom is not None:\n",
    "        x = wrap_time(keras.layers.experimental.preprocessing.RandomZoom(\n",
    "            height_factor=zoom, width_factor=zoom), single_step)(x)\n",
    "\n",
    "    if noise:\n",
    "        x = wrap_time(keras.layers.GaussianNoise(stddev=noise), single_step)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def generate_normalization_layers(x, single_step: bool):\n",
    "    rescaling_layer = keras.layers.experimental.preprocessing.Rescaling(1. / 255)\n",
    "\n",
    "    normalization_layer = keras.layers.experimental.preprocessing.Normalization(\n",
    "        mean=[0.6042006463205742, 0.6042006463205742, 0.6042006880578502],\n",
    "        variance=[0.0103, 0.0103, 0.0103])\n",
    "\n",
    "    x = rescaling_layer(x)\n",
    "    x = wrap_time(normalization_layer, single_step)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def wrap_time(layer, single_step: bool):\n",
    "    \"\"\"\n",
    "    Helper function that wraps layer in a timedistributed or not depending on the arguments of this function\n",
    "    \"\"\"\n",
    "    if not single_step:\n",
    "        return keras.layers.TimeDistributed(layer)\n",
    "    else:\n",
    "        return layer\n",
    "\n",
    "\n",
    "def generate_network_trunk(seq_len,\n",
    "                           image_shape,\n",
    "                           augmentation_params: Dict = None,\n",
    "                           batch_size=None,\n",
    "                           single_step: bool = False,\n",
    "                           no_norm_layer: bool = False, ):\n",
    "    \"\"\"\n",
    "    Generates CNN image processing backbone used in all recurrent models. Uses Keras.Functional API\n",
    "\n",
    "    returns input to be used in Keras.Model and x, a tensor that represents the output of the network that has shape\n",
    "    (batch [None], seq_len, num_units) if single step is false and (batch [None], num_units) if single step is true.\n",
    "    Input has shape (batch, h, w, c) if single step is True and (batch, seq, h, w, c) otherwise\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if single_step:\n",
    "        inputs = keras.Input(shape=image_shape)\n",
    "    else:\n",
    "        inputs = keras.Input(batch_input_shape=(batch_size, seq_len, *image_shape))\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    if not no_norm_layer:\n",
    "        x = generate_normalization_layers(x, single_step)\n",
    "\n",
    "    if augmentation_params is not None:\n",
    "        x = generate_augmentation_layers(x, augmentation_params, single_step)\n",
    "\n",
    "    # Conv Layers\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=24, kernel_size=(5, 5), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=36, kernel_size=(5, 5), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=48, kernel_size=(5, 5), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation='relu'), single_step)(\n",
    "        x)\n",
    "    x = wrap_time(keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(2, 2), activation='relu'), single_step)(\n",
    "        x)\n",
    "\n",
    "    # fully connected layers\n",
    "    x = wrap_time(keras.layers.Flatten(), single_step)(x)\n",
    "    x = wrap_time(keras.layers.Dense(units=128, activation='linear'), single_step)(x)\n",
    "    x = wrap_time(keras.layers.Dropout(rate=DROPOUT), single_step)(x)\n",
    "\n",
    "    return inputs, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "DROPOUT = 0.3\n",
    "\n",
    "class PPOModel(tf.keras.Model):\n",
    "    def __init__(self, seq_len, image_shape, augmentation_params=None, batch_size=None, single_step=False, no_norm_layer=False):\n",
    "        super(PPOModel, self).__init__()\n",
    "\n",
    "        # Generate the CNN trunk\n",
    "        self.inputs_image, self.cnn_features = generate_network_trunk(\n",
    "            seq_len,\n",
    "            image_shape,\n",
    "            augmentation_params=augmentation_params,\n",
    "            batch_size=batch_size,\n",
    "            single_step=single_step,\n",
    "            no_norm_layer=no_norm_layer,\n",
    "        )\n",
    "\n",
    "        # Actor Network (for velocity predictions)\n",
    "        self.actor_dense1 = layers.Dense(64, activation='relu')\n",
    "        self.actor_dense2 = layers.Dense(32, activation='relu')\n",
    "        self.actor_output = layers.Dense(4, activation='tanh')  # Outputs [v_x, v_y, v_z, omega_z]\n",
    "\n",
    "        # Critic Network (for value estimation)\n",
    "        self.critic_dense1 = layers.Dense(64, activation='relu')\n",
    "        self.critic_dense2 = layers.Dense(32, activation='relu')\n",
    "        self.critic_output = layers.Dense(1, activation='linear')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.cnn_features\n",
    "\n",
    "        # Actor forward pass\n",
    "        actor_hidden = self.actor_dense1(x)\n",
    "        actor_hidden = self.actor_dense2(actor_hidden)\n",
    "        actions = self.actor_output(actor_hidden)\n",
    "\n",
    "        # Critic forward pass\n",
    "        critic_hidden = self.critic_dense1(x)\n",
    "        critic_hidden = self.critic_dense2(critic_hidden)\n",
    "        value = self.critic_output(critic_hidden)\n",
    "\n",
    "        return actions, value\n",
    "\n",
    "def ppo_loss(old_probs, actions, advantages, clip_ratio=0.2):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        new_probs = tfd.MultivariateNormalDiag(loc=y_pred).log_prob(actions)\n",
    "        ratio = tf.exp(new_probs - old_probs)\n",
    "        clipped_ratio = tf.clip_by_value(ratio, 1 - clip_ratio, 1 + clip_ratio)\n",
    "        loss_actor = -tf.reduce_mean(tf.minimum(ratio * advantages, clipped_ratio * advantages))\n",
    "\n",
    "        # Critic loss (value estimation)\n",
    "        y_true_value, y_pred_value = y_true[:, -1], y_pred[:, -1]\n",
    "        loss_critic = keras.losses.MSE(y_true_value, y_pred_value)\n",
    "\n",
    "        return loss_actor + 0.5 * loss_critic\n",
    "\n",
    "    return loss_fn\n",
    "\n",
    "def build_ppo_model(seq_len, image_shape, augmentation_params=None, batch_size=None, single_step=False, no_norm_layer=False):\n",
    "    # Initialize the model\n",
    "    model = PPOModel(seq_len, image_shape, augmentation_params, batch_size, single_step, no_norm_layer)\n",
    "\n",
    "    # Compile the model with PPO loss\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels [[-5.45208991e-01  5.56323528e-01 -9.62745726e-01  5.51216781e-01]\n",
      " [-4.69735712e-01  5.59266984e-01 -8.87602270e-01  5.16884804e-01]\n",
      " [-3.96264791e-01  5.48152566e-01 -8.28002930e-01  4.87919092e-01]\n",
      " [-3.18426251e-01  5.24390161e-01 -7.62720525e-01  4.55274433e-01]\n",
      " [-2.60237217e-01  4.96815681e-01 -7.08253622e-01  4.27806526e-01]\n",
      " [-2.19786286e-01  4.72018570e-01 -6.70199931e-01  4.07966048e-01]\n",
      " [-1.71101779e-01  4.34729010e-01 -6.20564520e-01  3.81809920e-01]\n",
      " [-1.26528889e-01  3.93339336e-01 -5.77598214e-01  3.56382489e-01]\n",
      " [-9.09503549e-02  3.50732327e-01 -5.36118031e-01  3.34085882e-01]\n",
      " [-7.03007281e-02  3.23684692e-01 -5.10422289e-01  3.17597598e-01]\n",
      " [-4.33358178e-02  2.80392528e-01 -4.69446898e-01  2.94971615e-01]\n",
      " [-2.49505118e-02  2.43477389e-01 -4.32806820e-01  2.73863882e-01]\n",
      " [-1.16705829e-02  2.13092744e-01 -4.04083222e-01  2.56695092e-01]\n",
      " [-6.24483393e-04  1.82767749e-01 -3.74043435e-01  2.38524824e-01]\n",
      " [ 4.71147848e-03  1.65640324e-01 -3.56202573e-01  2.27526307e-01]\n",
      " [ 1.17294081e-02  1.36703879e-01 -3.23635995e-01  2.08152026e-01]\n",
      " [ 1.42659880e-02  1.24607354e-01 -3.09770733e-01  1.99230969e-01]\n",
      " [ 1.74455903e-02  1.05617389e-01 -2.86325336e-01  1.83139950e-01]\n",
      " [ 1.91526208e-02  9.07731429e-02 -2.67322004e-01  1.72291905e-01]\n",
      " [ 2.02777199e-02  7.81485662e-02 -2.47886926e-01  1.60277292e-01]\n",
      " [ 2.08312087e-02  6.75572753e-02 -2.31808066e-01  1.49402037e-01]\n",
      " [ 2.09933780e-02  5.77865802e-02 -2.15548053e-01  1.39007166e-01]\n",
      " [ 2.09325738e-02  5.06732278e-02 -2.01289669e-01  1.29026279e-01]\n",
      " [ 2.08475012e-02  4.38304879e-02 -1.86646536e-01  1.20160185e-01]\n",
      " [ 2.04349570e-02  3.82724553e-02 -1.73676521e-01  1.11396484e-01]\n",
      " [ 2.00814344e-02  3.33583616e-02 -1.61486208e-01  1.03257135e-01]\n",
      " [ 1.98481511e-02  2.98677273e-02 -1.50791436e-01  9.58207250e-02]\n",
      " [ 1.95822269e-02  2.77493373e-02 -1.43825874e-01  9.12735164e-02]\n",
      " [ 1.91418938e-02  2.43837573e-02 -1.30881995e-01  8.22767243e-02]\n",
      " [ 1.87277775e-02  2.22096983e-02 -1.22517094e-01  7.68597946e-02]\n",
      " [ 1.84869766e-02  2.08613481e-02 -1.17568791e-01  7.33709335e-02]\n",
      " [ 1.81706157e-02  1.93616394e-02 -1.09273277e-01  6.77120462e-02]\n",
      " [ 1.78787280e-02  1.82845425e-02 -1.04563303e-01  6.43558949e-02]\n",
      " [ 1.73404794e-02  1.65134277e-02 -9.44947898e-02  5.77173904e-02]\n",
      " [ 1.70352608e-02  1.56143187e-02 -8.99774134e-02  5.42263873e-02]\n",
      " [ 1.65796094e-02  1.45966103e-02 -8.38545635e-02  5.01956791e-02]\n",
      " [ 1.62614956e-02  1.39058363e-02 -7.96026215e-02  4.72793393e-02]\n",
      " [ 1.58252623e-02  1.30369123e-02 -7.38476440e-02  4.33416851e-02]\n",
      " [ 1.54562313e-02  1.22995395e-02 -6.84827045e-02  3.99791375e-02]\n",
      " [ 1.49066048e-02  1.14387581e-02 -6.44150153e-02  3.69227789e-02]\n",
      " [ 1.44224623e-02  1.07908333e-02 -6.05676658e-02  3.43040489e-02]\n",
      " [ 1.38962837e-02  1.00729018e-02 -5.62885664e-02  3.15091573e-02]\n",
      " [ 1.34646511e-02  9.61258169e-03 -5.35682626e-02  2.97169890e-02]\n",
      " [ 1.29588274e-02  8.95524956e-03 -5.00039607e-02  2.72882655e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "64\n",
      "no of imgs 64\n",
      "n bags: 1\n",
      "n windows: 0\n",
      "load dataset shape (TensorSpec(shape=(64, 144, 256, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(64, 4), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "shift: int = 1\n",
    "stride: int = 1\n",
    "# decay_rate: float = 0.95\n",
    "val_split: float = 0.2\n",
    "label_scale: float = 1\n",
    "seq_len = 64\n",
    "val_split: float = 0.1\n",
    "label_scale: float = 1\n",
    "\n",
    "training_dataset = get_dataset_multi(training_root, IMAGE_SHAPE, seq_len, shift, stride, val_split, label_scale, extra_data_root=None)\n",
    "print('load dataset shape', training_dataset.element_spec)\n",
    "training_dataset = training_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:757 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:598 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/utils.py:78 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0', 'dense_6/kernel:0', 'dense_6/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m build_ppo_model(seq_len, IMAGE_SHAPE, augmentation_params, batch_size, single_step, no_norm_layer)\n\u001b[1;32m     10\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(history)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:757 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:598 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/utils.py:78 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0', 'dense_6/kernel:0', 'dense_6/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "seq_len = 64\n",
    "augmentation_params = None\n",
    "single_step = False\n",
    "no_norm_layer = False\n",
    "\n",
    "\n",
    "model = build_ppo_model(seq_len, IMAGE_SHAPE, augmentation_params, batch_size, single_step, no_norm_layer)\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(x=training_dataset, epochs=epochs,verbose=1, use_multiprocessing=False, workers=1, max_queue_size=5)\n",
    "print(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
